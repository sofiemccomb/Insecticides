---
title: "Analysis"
author: "Sofie McComb"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This R Markdown document will perform the panel linear model regressions for determining the relationship of agricultural and landscape variables on insectide use. The regressions are performed in separate R scripts that are sourced below and than analyzed.


Current primary variables to be examined include:  

1. pland_crops
    * Percentage of county with cropland area, in percent 
2. cropintensity 
    * Harvested cropland acres per area of county cropland, in acres/acres
3. SDI
    * Crop diversity, 0-1 value
4. msidi
    * Simpson's landscape diversity, 0-1 value 
5. te_shared_c_nc 
    * Shared edge length between natural land and cropland divided by the total edge length of cropland, in   meters/meters
6. mna_crops
    * Mean patch size in hectares of cropland, in hectares
7. largefarm_planted
    * Acreage of harvested acres for farms >500acres, in acres 

Secondary variables to be examined include:  

1. crop covariates
    * soysmallgrain_planted + corn_planted + fruitveg_planted, all in acres 
 
Analyses are run for all counties pooled together (cp) and by Economic Research Service (ERS) Farm Resource Regions. County and Year fixed effects (and a combination of them) will be run for each regression.
Furthermore, two years (1997 and 2002) and missing data for SDI, so versions will be run excluding these purposefully.
Several combinations of variables and regressions will also be performed. 

## Data Preparation

This section will load the necessary packages and data, and run analyses on the data to examine the natural variation.

### Load Packages

```{r packages, message=F, warning=F}

#Load the needed packages (install first if necessary)
library(tidyverse) #Datatable manipulation
library(purrr) #For reduce function using full_join
library(plm) #Linear models for panel data
library(stats) #For as.formula function
library(car) # For calculating variance inflation factors (vif)
library(rlang) #For xtsum function creation
library(gdata) #For combine in xtsum function
library(ggplot2) #Data visualization
library(stargazer)#Regression and summary statistics tables

#Set options
options(scipen=999) #no scientific notation (all)

```


### Load Data

Loading the fulldata dataset created in the DataProcessing.Rmd, which was developed to perform the regression analyses.

```{r data, message=F, warning=F}

load("Data/DataProcessing/df/fulldata.rda")

```

### Examine Data with XTSUM

XTSUM (based on the stata function) examines the overall, within, and between variation found in a dataset.

```{r xtsum, message=F, warning=F}

#Source xtsumR script to examine variation within variables (fips, year) from fulldata and load saved analysis dataframe
source("R/Analysis/xtsumR.R")
#Script both creates R version of xtsum function and perform analyses, put into a dataframe and loaded here.
load("Data/Analysis/xtsum/xtsum_df.Rda")

```


## Run Panel Linear Model Regressions
Perform the regressions within separate R scripts, and have lists of the performed models loadable as rda file in order to perform analyses on the model results and create dataframes of results across models. All regressions are run using the "R/run_plm.R" script, which contains the run_plm function for performing panel linear model regressions. The script is sourced directly in the analysis scripts that are used below. The model inputs are created in each of the two scripts.

The general format is:  

run_plm<-function(predictors, data=fulldata,index = c("FIPS","Year"), model = "within",effect = "twoways"){
  Formula=stats::as.formula(paste("insect_planted ~ ", paste(predictors, collapse=" + ")))
  plm_model<-plm::plm(Formula, data = data,index = index,model = model,effect = effect)
  return(plm_model)}


Current versions of regressions to be performed for both pooled counties and by ERS regions include:  

1. Using all 7 primary variables
2. Using 6 primary variables, excluding SDI 
3. Using 6 primary variables, excluding SDI, but just for 2002-2017
4. All secondary crop covariates included
 
Twoways, individual, and time fixed effects models will be run for each regression, both as a within model and pooling model.

Default of regression is na.omit, so okay to currently rows with NA values as they will be excluded from the analysis by the regression functions. 

Metadata available as Data/Analysis/df/DF_Metadata.txt. File generally describes the columns available in each of the created csv outputs under Data/Analysis/df subfolders. 


### 1) Counties Pooled (cp)

The cpmodels script performs the plm models for all counties pooled together using the run_plm function/script, and the list of model results are loaded and analyzed below.

#### Run panel regressions and save outputs as list of models in RDA format to be loaded

```{r cpmodels, message=F, warning=F}

#Script runs the counties pooled (cp) regression models and creates .Rda file of list of plm models (edit models in R script)
source("R/Analysis/cpmodels.R") #Takes a few minutes to run both within and pooling models
  #Separated into multiple lists of models so that rda files were not too large for github (<100 MB)
load("Data/Analysis/models/CP/cpmodels_within.Rda") #Within model for steps 1-3 ( 7 and 6 primary varialbes)
load("Data/Analysis/models/CP/cpmodels_crops_within.Rda") #Pooling model for steps 1-3 ( 7 and 6 primary varialbes)
load("Data/Analysis/models/CP/cpmodels_pooling.Rda") #Within model for step 4 (rerun steps 1-3 with crop covariates)
load("Data/Analysis/models/CP/cpmodels_crops_pooling.Rda") #Pooling model for step 4 (rerun steps 1-3 with crop covariates)

```

#### Create dataframe of important model information from each model

https://cran.r-project.org/web/packages/broom/vignettes/broom.html
Use broom package to grab all 

```{r}

library(broom)
#Combine within and pooling lists of models together to perform analyses
cpmodelswithin<-c(cpmodels_within, cpmodels_crops_within)
cpmodelspooling<-c(cpmodels_pooling, cpmodels_crops_pooling)

#Example model
exmodl<-cpmodelswithin[[1]]

broom::tidy(exmodl)
broom::augment(exmodl)
broom::glance(exmodl)

cp_df<- cpmodelswithin[[1]] %>% 
    broom::tidy() %>%
    #by_2sd(mtcars) %>% #If need to rescale regression results for comparison?
    dplyr::mutate(model = "Model 1")

for (i in 2:length(cpmodelswithin)){
  cp_model<-cpmodelswithin[[i]]
  cp_df<-rbind(cp_df, cp_model %>% 
                 broom::tidy() %>% 
                 #by_2sd(mtcars) %>% #If need to rescale regression results for comparison?
                 mutate(model=paste("Model", i)))
}

#figure out way to rename models by giving it the list name it is on


#Including rest of script although this would be saved and brought in visualization
# Relabel predictors (they will appear as facet labels) (come back to this)
# cp_df <- cp_df %>% 
#   relabel_predictors(c("(Intercept)" = "Intercept",
#                      wt = "Weight",
#                      cyl = "Cylinders",
#                      disp = "Displacement",
#                      hp = "Horsepower",
#                      gear = "Gears",
#                      am = "Manual"))
 
# Generate a 'small multiple' plot
library(dotwhisker)
dotwhisker::small_multiple(cp_df) +
  theme_bw() + ylab("Coefficient Estimate") +
  geom_hline(yintercept = 0, colour = "grey60", linetype = 2) +
  ggtitle("Predicting Mileage") +
  theme(plot.title = element_text(face = "bold"), 
        legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1)) 

#https://cran.r-project.org/web/packages/dotwhisker/vignettes/dotwhisker-vignette.html
#Use source above to figure out grouping by twoways, individual, and fixed?

#Also figure out way to save these dataframes and to perfrom vif and correlation on these dataframes as well and save
#Then get rid of below stuff (send to myself to have it saved somewhere- or move it onto personal computer)


```




Say something about this way can give you a really good comparison across
TAKE FROM BELOW CERTAIN PARTS

```{r cp_df, message=F, warning=F}

#Combine within and pooling lists of models together to perform analyses
cpmodelswithin<-c(cpmodels_within, cpmodels_crops_within)
cpmodelspooling<-c(cpmodels_pooling, cpmodels_crops_pooling)

#Create dataframe of coefficients from each model (using within)
cp_coef_df<- lapply(cpmodelswithin,function(l){rownames_to_column(as.data.frame(l$coefficient), "variable")})%>%
  purrr::reduce(full_join, by = "variable") %>%
  setNames(c("variable", names(cpmodelswithin)))

#Create dataframe of standard error from each model (using within)
cp_se_df<- lapply(cpmodelswithin, function(l){rownames_to_column(as.data.frame(summary(l)$coefficients[,2]),"variable")}) %>%
  purrr::reduce(full_join, by = "variable") %>%
  setNames(c("variable", names(cpmodelswithin))) %>%
   mutate_if(is.numeric, round, digits=8)

#Create dataframe of p-values from each model (using within)
cp_pval_df<- lapply(cpmodelswithin, function(l){rownames_to_column(as.data.frame(summary(l)$coefficients[,4]),"variable")}) %>%
  purrr::reduce(full_join, by = "variable") %>%
  setNames(c("variable", names(cpmodelswithin))) %>%
   mutate_if(is.numeric, round, digits=5)

#Run variance inflation factor (vif) to look at multicollinearity between variables and look at correlation matrices
  #Can only run on model=pooling for plm
    #However, since vif is about examining indepdenent variables, theoretically there is less need to control for effects
    #VIF of 1=no correlation among predictors, >4 investigate, >10 serious correction

  #VIF on pooled data
  cp_vif<-lapply(cpmodelspooling, function(p){rownames_to_column(as.data.frame(car::vif(p)), "variable")}) %>%
    purrr::reduce(full_join, by = "variable") %>%
    setNames(c("variable", names(cpmodelspooling)))

  #Correlation matrix on within data
  cp_corr<-lapply(cpmodelswithin, function(v){cov2cor(v$vcov)})

#Write csv for each of the created dataframes and rda for the correlation matrix list (save under Data/Analysis/df/CP)
  write_csv(cp_coef_df, "Data/Analysis/df/CP/cp_coef_df.csv")
  write_csv(cp_se_df, "Data/Analysis/df/CP/cp_se_df.csv")
  write_csv(cp_pval_df, "Data/Analysis/df/CP/cp_pval_df.csv")
  write_csv(cp_vif, "Data/Analysis/df/CP/cp_vif.csv")
  save(cp_corr, file="Data/Analysis/df/CP/cp_corr.Rda")

```


### 2) By ERS Region

The ERS zones are:  

1. Heartland
2. Northern Crescent 
3. Northern Great Plains
4. Prairie Gateway
5. Eastern Uplands 
6. Souther Seaboard
7. Fruitful Rim
8. Basin and Range 
9. Mississippi Portal

 
#### Run panel regressions and save outputs as list of models in RDA format to be iterated through

```{r ERSmodels, message=FALSE, warning=FALSE}

#Script runs the ERS (cp) regression models subset by ERS and creates .Rda file of list of plm models (edit models in R script)
source("R/Analysis/ERSmodels.R") 
#Takes a few minutes to run both within and pooling models for all ERS separately
  #Separated out crop covariate models so that rda files were not too large for github

#Similar files to cpmodels created, but for each individual ERS regions (have same names so can loop through them)

```

#### Create dataframe of important model information from each model, saving per ERS and combining for all ERS

```{r ERS_df, message=F, warning=F}

#Iterate through the ERS region models and perform analyses/create df for each ERS before combining
ERS<-1:9 #9 ERS Regions (defined in Markdown)
  for (e in ERS){
    #Load all 4 models within each ERS subfolder, which will be overwritten for every ERS
    fn<-as.list(list.files(path=paste0("Data/Analysis/models/ERS/", e), full.names = TRUE ))
    lapply(fn,load,.GlobalEnv) #loaded 4 files: ERSmodels_within/pooling & ERSmodels_crops_within/pooling

    #Combine within and pooling lists of models together to perform analyses
    ERSmodelswithin<-c(ERSmodels_within, ERSmodels_crops_within)
    ERSmodelspooling<-c(ERSmodels_pooling, ERSmodels_crops_pooling)

    #Create dataframe of coefficients from each model (using within)
    ERS_coef_df<- lapply(ERSmodelswithin,function(l){rownames_to_column(as.data.frame(l$coefficient), "variable")})%>%
      purrr::reduce(full_join, by = "variable") %>%
      setNames(c("variable", names(ERSmodelswithin))) %>%
      mutate(ERS=e) %>%  #Add column for ERS code
      select(variable, ERS, everything()) #move predictor variable and ERS code to the beginning

    #Create dataframe of standard error from each model (using within)
    ERS_se_df<- lapply(ERSmodelswithin, function(l){rownames_to_column(as.data.frame(summary(l)$coefficients[,2]),"variable")})        %>% purrr::reduce(full_join, by = "variable") %>%
        setNames(c("variable", names(ERSmodelswithin))) %>%
        mutate_if(is.numeric, round, digits=8) %>%
        mutate(ERS=e) %>%  #Add column for ERS code
        select(variable, ERS, everything()) #move predictor variable and ERS code to the beginning

    #Create dataframe of p-values from each model (using within)
    ERS_pval_df<- lapply(ERSmodelswithin, function(l){rownames_to_column(as.data.frame(summary(l)$coefficients[,4]),"variable")})      %>% purrr::reduce(full_join, by = "variable") %>%
        setNames(c("variable", names(ERSmodelswithin))) %>%
        mutate_if(is.numeric, round, digits=5) %>%
        mutate(ERS=e) %>%  #Add column for ERS code
        select(variable, ERS, everything()) #move predictor variable and ERS code to the beginning

    #Run variance inflation factor (vif) to look at multicollinearity between variables and look at correlation matrices
      #Can only run on model=pooling for plm
        #However, since vif is about examining indepdenent variables, theoretically there is less need to control for effects
        #VIF of 1=no correlation among predictors, >4 investigate, >10 serious correction

      #VIF on pooled data
      ERS_vif<-lapply(ERSmodelspooling, function(p){rownames_to_column(as.data.frame(car::vif(p)), "variable")}) %>%
        purrr::reduce(full_join, by = "variable") %>%
        setNames(c("variable", names(ERSmodelspooling))) %>%
        mutate(ERS=e) %>%  #Add column for ERS code
        select(variable, ERS, everything()) #move predictor variable and ERS code to the beginning

      #Correlation matrix on within data
      ERS_corr<-lapply(ERSmodelswithin, function(v){cov2cor(v$vcov)}) #will save in correct folder but not combine across ERS

    #Write csv for each of the created dataframes and rda for the correlation matrix list (save under Data/Analysis/df/ERS)
      write_csv(ERS_coef_df, paste0("Data/Analysis/df/ERS/", e ,"/ERS_coef_df.csv"))
      write_csv(ERS_se_df, paste0("Data/Analysis/df/ERS/", e ,"/ERS_se_df.csv"))
      write_csv(ERS_pval_df, paste0("Data/Analysis/df/ERS/", e ,"/ERS_pval_df.csv"))
      write_csv(ERS_vif, paste0("Data/Analysis/df/ERS/", e ,"/ERS_vif.csv"))
      save(ERS_corr, file=paste0("Data/Analysis/df/ERS/", e ,"/ERS_corr.Rda"))
  }

#Read in the dataframe for each ERS and rbind to create combined dataframe (coefficients, pvals, and vif)
  #ERS_coef_df
    coef_files <- list.files(pattern='ERS_coef_df.csv', recursive=TRUE, full.names = TRUE)
    ERS_coef_all <- do.call(rbind , lapply(coef_files, readr::read_csv)) %>%
      dplyr::arrange(variable) #order by variable so ERS together

   #ERS_se_df
    se_files <- list.files(pattern='ERS_se_df.csv', recursive=TRUE, full.names = TRUE)
    ERS_se_all <- do.call(rbind , lapply(se_files, readr::read_csv)) %>%
      dplyr::arrange(variable) #order by variable so ERS together

  #ERS_pval_df
    pval_files <- list.files(pattern='ERS_pval_df.csv', recursive=TRUE, full.names = TRUE)
    ERS_pval_all <- do.call(rbind , lapply(pval_files, readr::read_csv)) %>%
      dplyr::arrange(variable) #order by variable so ERS together

  #ERS_vif
    vif_files <- list.files(pattern='ERS_vif.csv', recursive=TRUE, full.names = TRUE)
    ERS_vif_all <- do.call(rbind , lapply(vif_files, readr::read_csv)) %>%
      dplyr::arrange(variable) #order by variable so ERS together

#Write combined df to csv files under Data/Analysis/df/ERS as all files
  write_csv(ERS_coef_all, "Data/Analysis/df/ERS/ERS_coef_all.csv")
  write_csv(ERS_se_all, "Data/Analysis/df/ERS/ERS_se_all.csv")
  write_csv(ERS_pval_all, "Data/Analysis/df/ERS/ERS_pval_all.csv")
  write_csv(ERS_vif_all, "Data/Analysis/df/ERS/ERS_vif_all.csv")

```


